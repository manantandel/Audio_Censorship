{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:25.108248Z",
     "iopub.status.busy": "2024-10-05T18:52:25.107939Z",
     "iopub.status.idle": "2024-10-05T18:52:41.337999Z",
     "shell.execute_reply": "2024-10-05T18:52:41.337030Z",
     "shell.execute_reply.started": "2024-10-05T18:52:25.108215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:41.340748Z",
     "iopub.status.busy": "2024-10-05T18:52:41.339829Z",
     "iopub.status.idle": "2024-10-05T18:52:41.344924Z",
     "shell.execute_reply": "2024-10-05T18:52:41.344006Z",
     "shell.execute_reply.started": "2024-10-05T18:52:41.340699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Load the datasets\n",
    "try_data_path = r'try.csv'\n",
    "badwordlist_data_path = r'BadWordList.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:41.346266Z",
     "iopub.status.busy": "2024-10-05T18:52:41.346002Z",
     "iopub.status.idle": "2024-10-05T18:52:41.400020Z",
     "shell.execute_reply": "2024-10-05T18:52:41.399232Z",
     "shell.execute_reply.started": "2024-10-05T18:52:41.346237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try_df = pd.read_csv(try_data_path)\n",
    "badwordlist_df = pd.read_csv(badwordlist_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:41.402437Z",
     "iopub.status.busy": "2024-10-05T18:52:41.402129Z",
     "iopub.status.idle": "2024-10-05T18:52:41.411387Z",
     "shell.execute_reply": "2024-10-05T18:52:41.410495Z",
     "shell.execute_reply.started": "2024-10-05T18:52:41.402404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Extract bad words and sentences\n",
    "badwords_devanagari = badwordlist_df['Devanagari'].dropna().tolist()\n",
    "sentences = try_df['Filtered Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:41.412535Z",
     "iopub.status.busy": "2024-10-05T18:52:41.412284Z",
     "iopub.status.idle": "2024-10-05T18:52:41.421827Z",
     "shell.execute_reply": "2024-10-05T18:52:41.421004Z",
     "shell.execute_reply.started": "2024-10-05T18:52:41.412505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to check if a sentence contains any bad words\n",
    "def contains_badword(sentence, badword_list):\n",
    "    for word in badword_list:\n",
    "        if re.search(r'\\b' + re.escape(word) + r'\\b', sentence):\n",
    "            return 1  # Contains a bad word\n",
    "    return 0  # No bad word found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:41.423473Z",
     "iopub.status.busy": "2024-10-05T18:52:41.422930Z",
     "iopub.status.idle": "2024-10-05T18:52:44.124462Z",
     "shell.execute_reply": "2024-10-05T18:52:44.123665Z",
     "shell.execute_reply.started": "2024-10-05T18:52:41.423432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Annotate sentences with bad word labels\n",
    "try_df['contains_badword'] = sentences.apply(lambda x: contains_badword(x, badwords_devanagari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.125791Z",
     "iopub.status.busy": "2024-10-05T18:52:44.125524Z",
     "iopub.status.idle": "2024-10-05T18:52:44.206994Z",
     "shell.execute_reply": "2024-10-05T18:52:44.206304Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.125761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. Tokenize and pad sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(try_df['Filtered Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.208270Z",
     "iopub.status.busy": "2024-10-05T18:52:44.207961Z",
     "iopub.status.idle": "2024-10-05T18:52:44.265757Z",
     "shell.execute_reply": "2024-10-05T18:52:44.264999Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.208239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert sentences to sequences of token IDs\n",
    "sequences = tokenizer.texts_to_sequences(try_df['Filtered Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.267073Z",
     "iopub.status.busy": "2024-10-05T18:52:44.266764Z",
     "iopub.status.idle": "2024-10-05T18:52:44.280117Z",
     "shell.execute_reply": "2024-10-05T18:52:44.279240Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.267041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure uniform length\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.283611Z",
     "iopub.status.busy": "2024-10-05T18:52:44.283266Z",
     "iopub.status.idle": "2024-10-05T18:52:44.287663Z",
     "shell.execute_reply": "2024-10-05T18:52:44.286853Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.283581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Prepare the labels\n",
    "y = try_df['contains_badword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.288911Z",
     "iopub.status.busy": "2024-10-05T18:52:44.288658Z",
     "iopub.status.idle": "2024-10-05T18:52:44.304034Z",
     "shell.execute_reply": "2024-10-05T18:52:44.303208Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.288882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.305422Z",
     "iopub.status.busy": "2024-10-05T18:52:44.305131Z",
     "iopub.status.idle": "2024-10-05T18:52:44.310449Z",
     "shell.execute_reply": "2024-10-05T18:52:44.309491Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.305391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 7. Build the LSTM model\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size for embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:44.311926Z",
     "iopub.status.busy": "2024-10-05T18:52:44.311574Z",
     "iopub.status.idle": "2024-10-05T18:52:45.182920Z",
     "shell.execute_reply": "2024-10-05T18:52:45.181987Z",
     "shell.execute_reply.started": "2024-10-05T18:52:44.311892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_sequence_length),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (badword or not)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:45.184565Z",
     "iopub.status.busy": "2024-10-05T18:52:45.184186Z",
     "iopub.status.idle": "2024-10-05T18:52:45.205146Z",
     "shell.execute_reply": "2024-10-05T18:52:45.204416Z",
     "shell.execute_reply.started": "2024-10-05T18:52:45.184508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 8. Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:52:45.206312Z",
     "iopub.status.busy": "2024-10-05T18:52:45.206067Z",
     "iopub.status.idle": "2024-10-05T18:53:02.212235Z",
     "shell.execute_reply": "2024-10-05T18:53:02.211342Z",
     "shell.execute_reply.started": "2024-10-05T18:52:45.206284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.5892 - loss: 0.6864 - val_accuracy: 0.5737 - val_loss: 0.6648\n",
      "Epoch 2/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7576 - loss: 0.5262 - val_accuracy: 0.6653 - val_loss: 0.7810\n",
      "Epoch 3/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9527 - loss: 0.1545 - val_accuracy: 0.6773 - val_loss: 0.7840\n",
      "Epoch 4/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.0206 - val_accuracy: 0.6932 - val_loss: 1.0132\n",
      "Epoch 5/5\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9817 - loss: 0.0406 - val_accuracy: 0.7570 - val_loss: 1.2287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a7ddb18b5e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=8, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:53:02.213558Z",
     "iopub.status.busy": "2024-10-05T18:53:02.213274Z",
     "iopub.status.idle": "2024-10-05T18:53:02.354450Z",
     "shell.execute_reply": "2024-10-05T18:53:02.353621Z",
     "shell.execute_reply.started": "2024-10-05T18:53:02.213528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7779 - loss: 1.2037 \n",
      "Test Accuracy: 75.70%\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:55:05.662606Z",
     "iopub.status.busy": "2024-10-05T18:55:05.661950Z",
     "iopub.status.idle": "2024-10-05T18:55:05.666665Z",
     "shell.execute_reply": "2024-10-05T18:55:05.665756Z",
     "shell.execute_reply.started": "2024-10-05T18:55:05.662567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_sentence = \"तेरी रंडी माँ की चूत\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:55:05.890310Z",
     "iopub.status.busy": "2024-10-05T18:55:05.889948Z",
     "iopub.status.idle": "2024-10-05T18:55:05.894581Z",
     "shell.execute_reply": "2024-10-05T18:55:05.893615Z",
     "shell.execute_reply.started": "2024-10-05T18:55:05.890275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize and pad the test sentence\n",
    "test_sequence = tokenizer.texts_to_sequences([test_sentence])\n",
    "test_sequence_padded = pad_sequences(test_sequence, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:55:06.078066Z",
     "iopub.status.busy": "2024-10-05T18:55:06.077728Z",
     "iopub.status.idle": "2024-10-05T18:55:06.147301Z",
     "shell.execute_reply": "2024-10-05T18:55:06.146511Z",
     "shell.execute_reply.started": "2024-10-05T18:55:06.078032Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict if it contains a bad word\n",
    "prediction = model.predict(test_sequence_padded)\n",
    "predicted_label = (prediction > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:55:06.490332Z",
     "iopub.status.busy": "2024-10-05T18:55:06.489905Z",
     "iopub.status.idle": "2024-10-05T18:55:06.495592Z",
     "shell.execute_reply": "2024-10-05T18:55:06.494654Z",
     "shell.execute_reply.started": "2024-10-05T18:55:06.490294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence contains bad words.\n"
     ]
    }
   ],
   "source": [
    "if predicted_label[0][0] == 1:\n",
    "    print(\"The sentence contains bad words.\")\n",
    "else:\n",
    "    print(\"The sentence does not contain bad words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening audio file: file does not start with RIFF id\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Debug: print the full structure of the results\n",
    "    # print(json.dumps(results, indent=4))\n",
    "\n",
    "    # Extract and print transcription with timestamps\n",
    "    for result in results:\n",
    "        if 'result' in result:  # Checking if word-level info is present\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "transcribe_audio_with_timestamps(r'Audio_Data\\Audio_9.mp3', 'vosk-model-hi-0.22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file must be WAV format mono PCM.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    # Convert MP3 file to WAV using pydub\n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Check if the audio file is in WAV format\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract and print transcription with timestamps\n",
    "    for result in results:\n",
    "        if 'result' in result:  # Checking if word-level info is present\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "transcribe_audio_with_timestamps(r'audio.mp3', 'vosk-model-hi-0.22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio...\n",
      "Word: अबे, Start: 0.60s, End: 0.90s\n",
      "Word: साले, Start: 0.90s, End: 1.23s\n",
      "Word: तेरी, Start: 1.23s, End: 1.47s\n",
      "Word: माँ, Start: 1.47s, End: 1.62s\n",
      "Word: की, Start: 1.62s, End: 1.77s\n",
      "Word: चूत, Start: 1.83s, End: 2.16s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)  # Use PCM codec for export\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Check if the audio file is in WAV format\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract and print transcription with timestamps\n",
    "    for result in results:\n",
    "        if 'result' in result:  # Checking if word-level info is present\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "transcribe_audio_with_timestamps(r'myfile.wav', 'vosk-model-small-hi-0.22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "convert_mp3_to_wav(\"Test2.wav\", \"myfile.wav\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5822556,
     "sourceId": 9555597,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
