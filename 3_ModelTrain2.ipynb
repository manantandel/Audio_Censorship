{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('annotated_bad_words.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def extract_labels(sentence):\n",
    "    words = sentence.split()\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    \n",
    "    for word in words:\n",
    "        if \"<bad_word>\" in word:\n",
    "            word = word.replace(\"<bad_word>\", \"\").replace(\"</bad_word>\", \"\")\n",
    "            labels.append(1)  # Label '1' for bad word\n",
    "        else:\n",
    "            labels.append(0)  # Label '0' for normal word\n",
    "        tokens.append(word)\n",
    "    \n",
    "    return \" \".join(tokens), labels\n",
    "\n",
    "# Apply label extraction\n",
    "data['Processed Sentences'], data['Labels'] = zip(*data['Annotated Sentences'].apply(extract_labels))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "sentences = data['Processed Sentences'].tolist()\n",
    "labels = data['Labels'].tolist()\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Convert text to sequences and pad them\n",
    "max_length = max(len(seq) for seq in sequences)  \n",
    "print(max_length) # Define max length for padding\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Pad the labels as well to match max_length\n",
    "train_labels_padded = pad_sequences(train_labels, maxlen=max_length, padding='post', truncating='post')\n",
    "test_labels_padded = pad_sequences(test_labels, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Load pre-trained fastText Hindi embeddings\n",
    "embedding_index = {}\n",
    "embedding_dim = 300  # fastText embeddings are typically 300-dimensional\n",
    "\n",
    "# Path to the fastText Hindi embedding file (e.g., \"cc.hi.300.vec\")\n",
    "with open(\"cc.hi.300.vec\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embedding_index[word] = vector\n",
    "\n",
    "# Prepare the embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build the model with pre-trained embeddings\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_length,\n",
    "        trainable=False  # Set to True if you want to fine-tune embeddings\n",
    "    ),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu')),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_padded, train_labels_padded, epochs=5, validation_data=(test_padded, test_labels_padded))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_padded, test_labels_padded)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocesses a single sentence by tokenizing and padding.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    \n",
    "    # Pad the sequence to match the max_length\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    \n",
    "    return padded_sequence\n",
    "\n",
    "def predict_bad_words(sentence):\n",
    "    \"\"\"\n",
    "    Predicts bad words in a new sentence.\n",
    "    \"\"\"\n",
    "    # Preprocess the sentence\n",
    "    padded_sequence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # Get predictions from the model\n",
    "    predictions = model.predict(padded_sequence)\n",
    "    \n",
    "    # Threshold to classify as bad word or not\n",
    "    threshold = 0.5\n",
    "    predicted_labels = (predictions > threshold).astype(int)[0]\n",
    "    \n",
    "    # Print out each word with its prediction\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words[:max_length]):\n",
    "        is_bad_word = \"Bad Word\" if predicted_labels[i] == 1 else \"Normal Word\"\n",
    "        print(f\"{word}: {is_bad_word}\")\n",
    "\n",
    "# Example sentence in Hindi containing some abusive words\n",
    "new_sentence = \"तू खुद को क्या समझता है, चूतिया साला? हर बार बकवास करता है और दूसरों को परेशान करता है। कमीने, तमीज से पेश आ।\"\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the new sentence\n",
    "predict_bad_words(new_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\manan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_layer', 'input_layer_1']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B7EDD72B60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B7EDD72B60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "Detected Bad Words: गांडू, मादरचोद\n",
      "['गांडू', 'मादरचोद']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# Load the tokenizers\n",
    "with open('w2v_word_tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "with open('w2v_char_tokenizer.pkl', 'rb') as handle:\n",
    "    char_tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('word2vec_bad_model.h5')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocesses a single sentence by tokenizing and padding for both word and character levels.\n",
    "    \"\"\"\n",
    "    char_max_length = 15\n",
    "    max_length = 475\n",
    "    \n",
    "    # Tokenize the sentence for words\n",
    "    word_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_word_sequence = pad_sequences(word_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    \n",
    "    # Tokenize and pad character sequences for each word\n",
    "    char_sequence = [[char_tokenizer.word_index.get(char, 0) for char in word] for word in sentence.split()]\n",
    "    char_sequence = pad_sequences(char_sequence, maxlen=char_max_length, padding=\"post\")\n",
    "    \n",
    "    # Pad the entire sequence of words to ensure uniformity\n",
    "    padded_char_sequence = pad_sequences([char_sequence], maxlen=max_length, padding='post', dtype='int32')\n",
    "\n",
    "    return padded_word_sequence, padded_char_sequence\n",
    "\n",
    "def predict_bad_words(sentence):\n",
    "    \"\"\"\n",
    "    Predicts bad words in a new sentence using the trained model and returns a list of detected bad words.\n",
    "    \"\"\"\n",
    "    max_length = 475\n",
    "    \n",
    "    # Preprocess the sentence\n",
    "    padded_word_sequence, padded_char_sequence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # Get predictions from the model\n",
    "    predictions = model.predict([padded_word_sequence, padded_char_sequence])\n",
    "    \n",
    "    # Threshold to classify as bad word or not\n",
    "    threshold = 0.5\n",
    "    predicted_labels = (predictions > threshold).astype(int)[0]  # Flatten the predictions array\n",
    "    \n",
    "    # Extract and print only bad words\n",
    "    words = sentence.split()\n",
    "    bad_words = [word for i, word in enumerate(words[:max_length]) if predicted_labels[i] == 1]\n",
    "    # Print the bad words\n",
    "    if bad_words:\n",
    "        print(\"Detected Bad Words:\", \", \".join(bad_words))\n",
    "    else:\n",
    "        print(\"No bad words detected.\")\n",
    "\n",
    "    return bad_words\n",
    "\n",
    "# Example sentence in Hindi containing some abusive words\n",
    "new_sentence = \"तू हमेशा दूसरों को चुतिये और गांडू बोलता है, खुद हर बात में फुद्दी की बातें करता है, मादरचोद\"\n",
    "# Predict and get the list of bad words\n",
    "bad_words_list = predict_bad_words(new_sentence)\n",
    "\n",
    "print(bad_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)  # Use PCM codec for export\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Check if the audio file is in WAV format\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    for result in results:\n",
    "        if 'result' in result:  \n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "transcribe_audio_with_timestamps(r'myfile.wav', 'vosk-model-small-hi-0.22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio...\n",
      "Transcribed Sentence: इस रंडी साली जिससे कोई भी मुल्ला मौलवी और घोडों ने चोदने से नहीं छोडा यह मंदिर को अपवित्र करने की गई और किस दोगले पंडित ने इसकी पूजा कराई यह हिन्दू नहीं है पता नहीं कितने कुछ बातों से सोनिया भोसड़ी छुडवाकर इस हाइब्रिड और राहुल गांधी पप्पू को पैदा किया इसके चूत की प्यास नहीं बुझी है सालों को जेल में रहना चाहिए ये देशद्रोही गद्दार हिंदू विरोधी और देश के सबसे बड़े दुश्मन है अगर जरा भी देश से प्रेम होता तो प्रियंका की शादी किसी हिन्दू से करती यह राजीव गांधी फैंस का चौथा पता नहीं इंदिरा गाँधी ने कितने लोगों से चुदवा कर इस नमूने को पैदा किया था जिस मात्र चोट को इस देश में झंडी नहीं मिली जाकर इन तीनों मारिया जैसी महानदी को ले आया ये देश के गद्दार और देशद्रोही और पाकिस्तान पर थे जय भारत जय भीम वंदे मातरम जय हिंद नेहरू गांधी और इंदिरा भोसड़ी के इस परिवार का समूल नाश में ही देश की भलाई है\n",
      "Word Timestamps (JSON): {'इस': {'start': 52.32, 'end': 52.56}, 'रंडी': {'start': 0.27, 'end': 0.57}, 'साली': {'start': 0.57, 'end': 0.9}, 'जिससे': {'start': 0.9, 'end': 1.23}, 'कोई': {'start': 1.23, 'end': 1.47}, 'भी': {'start': 25.41, 'end': 25.56}, 'मुल्ला': {'start': 1.62, 'end': 1.92}, 'मौलवी': {'start': 1.92, 'end': 2.31}, 'और': {'start': 51.18, 'end': 51.36}, 'घोडों': {'start': 2.55, 'end': 2.85}, 'ने': {'start': 33.27, 'end': 33.42}, 'चोदने': {'start': 3.0, 'end': 3.36}, 'से': {'start': 34.08, 'end': 34.261414}, 'नहीं': {'start': 38.31, 'end': 38.52}, 'छोडा': {'start': 3.81, 'end': 4.11}, 'यह': {'start': 30.15, 'end': 30.36}, 'मंदिर': {'start': 4.32, 'end': 4.65}, 'को': {'start': 40.77, 'end': 40.92}, 'अपवित्र': {'start': 4.8, 'end': 5.31}, 'करने': {'start': 5.31, 'end': 5.58}, 'की': {'start': 54.96, 'end': 55.08}, 'गई': {'start': 5.79, 'end': 6.0}, 'किस': {'start': 6.210153, 'end': 6.42226}, 'दोगले': {'start': 6.45, 'end': 6.84}, 'पंडित': {'start': 6.84, 'end': 7.17}, 'इसकी': {'start': 7.35, 'end': 7.65}, 'पूजा': {'start': 7.65, 'end': 7.98}, 'कराई': {'start': 7.98, 'end': 8.34}, 'हिन्दू': {'start': 28.68, 'end': 28.98}, 'है': {'start': 55.44, 'end': 55.65}, 'पता': {'start': 32.01, 'end': 32.28}, 'कितने': {'start': 33.42, 'end': 33.78}, 'कुछ': {'start': 10.934494, 'end': 11.131241}, 'बातों': {'start': 11.131241, 'end': 11.37}, 'सोनिया': {'start': 11.55, 'end': 11.94}, 'भोसड़ी': {'start': 11.97, 'end': 12.33}, 'छुडवाकर': {'start': 12.33, 'end': 12.989999}, 'हाइब्रिड': {'start': 13.23, 'end': 13.65}, 'राहुल': {'start': 13.86, 'end': 14.13}, 'गांधी': {'start': 50.79, 'end': 51.15}, 'पप्पू': {'start': 14.49, 'end': 14.82}, 'पैदा': {'start': 35.7, 'end': 35.97}, 'किया': {'start': 35.97, 'end': 36.24}, 'इसके': {'start': 16.2, 'end': 16.53}, 'चूत': {'start': 16.53, 'end': 16.77}, 'प्यास': {'start': 17.01, 'end': 17.28}, 'बुझी': {'start': 17.79, 'end': 18.03}, 'सालों': {'start': 19.02, 'end': 19.38}, 'जेल': {'start': 19.53, 'end': 19.77}, 'में': {'start': 54.42, 'end': 54.57}, 'रहना': {'start': 19.92, 'end': 20.22}, 'चाहिए': {'start': 20.22, 'end': 20.553234}, 'ये': {'start': 42.06, 'end': 42.27}, 'देशद्रोही': {'start': 43.23, 'end': 43.86}, 'गद्दार': {'start': 42.66, 'end': 43.05}, 'हिंदू': {'start': 21.69, 'end': 21.99}, 'विरोधी': {'start': 21.99, 'end': 22.41}, 'देश': {'start': 54.72, 'end': 54.96}, 'के': {'start': 52.11, 'end': 52.26}, 'सबसे': {'start': 23.039321, 'end': 23.37}, 'बड़े': {'start': 23.4, 'end': 23.61}, 'दुश्मन': {'start': 23.64, 'end': 24.0}, 'अगर': {'start': 24.9, 'end': 25.17}, 'जरा': {'start': 25.17, 'end': 25.41}, 'प्रेम': {'start': 25.98, 'end': 26.28}, 'होता': {'start': 26.28, 'end': 26.55}, 'तो': {'start': 26.55, 'end': 26.79}, 'प्रियंका': {'start': 27.48, 'end': 27.9}, 'शादी': {'start': 28.05, 'end': 28.38}, 'किसी': {'start': 28.38, 'end': 28.65}, 'करती': {'start': 29.13, 'end': 29.49}, 'राजीव': {'start': 30.39, 'end': 30.78}, 'फैंस': {'start': 31.14, 'end': 31.38}, 'का': {'start': 53.67, 'end': 53.82}, 'चौथा': {'start': 31.53, 'end': 32.01}, 'इंदिरा': {'start': 51.39, 'end': 51.72}, 'गाँधी': {'start': 32.91, 'end': 33.27}, 'लोगों': {'start': 33.78, 'end': 34.08}, 'चुदवा': {'start': 34.261414, 'end': 34.74}, 'कर': {'start': 34.74, 'end': 34.95}, 'नमूने': {'start': 35.16, 'end': 35.55}, 'था': {'start': 36.24, 'end': 36.42}, 'जिस': {'start': 36.42, 'end': 36.63}, 'मात्र': {'start': 36.66, 'end': 36.99}, 'चोट': {'start': 36.99, 'end': 37.23}, 'झंडी': {'start': 38.01, 'end': 38.31}, 'मिली': {'start': 38.55, 'end': 38.79}, 'जाकर': {'start': 38.79, 'end': 39.12}, 'इन': {'start': 39.18, 'end': 39.33}, 'तीनों': {'start': 39.33, 'end': 39.57}, 'मारिया': {'start': 39.6, 'end': 39.93}, 'जैसी': {'start': 39.93, 'end': 40.23}, 'महानदी': {'start': 40.230634, 'end': 40.77}, 'ले': {'start': 40.920754, 'end': 41.07}, 'आया': {'start': 41.071531, 'end': 41.43}, 'पाकिस्तान': {'start': 44.07, 'end': 44.61}, 'पर': {'start': 44.61, 'end': 44.79}, 'थे': {'start': 44.88, 'end': 45.15}, 'जय': {'start': 49.2, 'end': 49.485396}, 'भारत': {'start': 46.17, 'end': 46.59}, 'भीम': {'start': 46.83, 'end': 47.1}, 'वंदे': {'start': 47.73, 'end': 48.09}, 'मातरम': {'start': 48.09, 'end': 48.57}, 'हिंद': {'start': 49.5, 'end': 49.77}, 'नेहरू': {'start': 50.43, 'end': 50.76}, 'भोसड़ी': {'start': 51.75, 'end': 52.11}, 'परिवार': {'start': 53.25, 'end': 53.67}, 'समूल': {'start': 53.82, 'end': 54.18}, 'नाश': {'start': 54.18, 'end': 54.42}, 'ही': {'start': 54.57, 'end': 54.69}, 'भलाई': {'start': 55.08, 'end': 55.44}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return None, {}\n",
    "\n",
    "    model = Model(model_path)\n",
    "\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return None, {}\n",
    "\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return None, {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return None, {}\n",
    "    \n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    transcribed_text = \"\"\n",
    "    word_timestamps = {}\n",
    "\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    for result in results:\n",
    "        if 'result' in result:  \n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                \n",
    "                transcribed_text += word + \" \"\n",
    "                \n",
    "                word_timestamps[word] = {'start': start_time, 'end': end_time}\n",
    "\n",
    "    transcribed_text = transcribed_text.strip()\n",
    "\n",
    "    return transcribed_text, word_timestamps\n",
    "\n",
    "transcribed_sentence, timestamps = transcribe_audio_with_timestamps(r\"M:\\Coding\\NLP_Project\\AudioData\\Audio_7618.wav\", 'vosk-model-small-hi-0.22')\n",
    "if transcribed_sentence:\n",
    "    print(\"Transcribed Sentence:\", transcribed_sentence)\n",
    "    \n",
    "\n",
    "    print(\"Word Timestamps (JSON):\", timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "c:\\Users\\manan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_layer', 'input_layer_1']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
      "['हमारे', 'चूत', 'भोसड़ी', 'मारते', 'रंडी', 'चूत', 'मार', 'दलाल', 'रंडी', 'गांड', 'गांडू', 'लंड', 'लंड', 'गांड', 'चोदने', 'लंड', 'चूत', 'लंड', 'लौड़ा', 'लंड', 'लंड', 'हमारा', 'लंड', 'गांड', 'लंड', 'चूत']\n",
      "Muted audio saved to: muted_Audio_3009.wav\n"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Load the tokenizers and model (assuming they're saved as shown earlier)\n",
    "with open('w2v_word_tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('w2v_char_tokenizer.pkl', 'rb') as handle:\n",
    "    char_tokenizer = pickle.load(handle)\n",
    "model = load_model('word2vec_bad_model.h5')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    char_max_length = 15\n",
    "    max_length = 475\n",
    "    word_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_word_sequence = pad_sequences(word_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    char_sequence = [[char_tokenizer.word_index.get(char, 0) for char in word] for word in sentence.split()]\n",
    "    char_sequence = pad_sequences(char_sequence, maxlen=char_max_length, padding=\"post\")\n",
    "    padded_char_sequence = pad_sequences([char_sequence], maxlen=max_length, padding='post', dtype='int32')\n",
    "    return padded_word_sequence, padded_char_sequence\n",
    "\n",
    "def predict_bad_words(sentence):\n",
    "    max_length = 475\n",
    "    padded_word_sequence, padded_char_sequence = preprocess_sentence(sentence)\n",
    "    predictions = model.predict([padded_word_sequence, padded_char_sequence])\n",
    "    threshold = 0.5\n",
    "    predicted_labels = (predictions > threshold).astype(int)[0]\n",
    "    words = sentence.split()\n",
    "    bad_words = [word for i, word in enumerate(words[:max_length]) if predicted_labels[i] == 1]\n",
    "    return bad_words\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return []\n",
    "    \n",
    "    model = Model(model_path)\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return []\n",
    "    \n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "    \n",
    "    word_timestamps = []\n",
    "    for result in results:\n",
    "        if 'result' in result:\n",
    "            for word_info in result['result']:\n",
    "                word_timestamps.append({\n",
    "                    'word': word_info.get('word', ''),\n",
    "                    'start': word_info.get('start', 0),\n",
    "                    'end': word_info.get('end', 0)\n",
    "                })\n",
    "    return word_timestamps\n",
    "\n",
    "def mute_bad_words_in_audio(audio_file, bad_words, word_timestamps):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    for item in word_timestamps:\n",
    "        if item['word'] in bad_words:\n",
    "            start_ms = item['start'] * 1000\n",
    "            end_ms = item['end'] * 1000\n",
    "            audio = audio[:start_ms] + AudioSegment.silent(duration=(end_ms - start_ms)) + audio[end_ms:]\n",
    "    muted_file = \"muted_\" + os.path.basename(audio_file)\n",
    "    audio.export(muted_file, format=\"wav\")\n",
    "    return muted_file\n",
    "\n",
    "# Integrate all steps\n",
    "audio_file = r\"M:\\Coding\\NLP_Project\\AudioData\\Audio_3009.wav\"\n",
    "model_path = 'vosk-model-small-hi-0.22'\n",
    "\n",
    "# Step 1: Transcribe audio with timestamps\n",
    "word_timestamps = transcribe_audio_with_timestamps(audio_file, model_path)\n",
    "\n",
    "# Step 2: Detect bad words from transcribed text\n",
    "transcribed_text = \" \".join([item['word'] for item in word_timestamps])  # Create sentence from transcribed words\n",
    "bad_words = predict_bad_words(transcribed_text)\n",
    "print(bad_words)\n",
    "\n",
    "# Step 3: Mute bad words in audio\n",
    "muted_file = mute_bad_words_in_audio(audio_file, bad_words, word_timestamps)\n",
    "print(f\"Muted audio saved to: {muted_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "['हमारे', 'चूत', 'भोसड़ी', 'मूठ', 'मारते', 'रंडी', 'चूत', 'मार', 'दलाल', 'रंडी', 'गांड', 'गांडू', 'लंड', 'लंड', 'गांड', 'चोदने', 'लंड', 'चूत', 'लंड', 'लौड़ा', 'लंड', 'लंड', 'हमारा', 'लंड', 'गांड', 'चूतड़ों', 'लंड', 'चूत']\n",
      "Muted audio saved to: muted_Audio_3009.wav\n"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Load the tokenizers and model (assuming they're saved as shown earlier)\n",
    "with open('ft_word_tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('ft_char_tokenizer.pkl', 'rb') as handle:\n",
    "    char_tokenizer = pickle.load(handle)\n",
    "model = load_model('fast_text_bad_word_detection_model.h5')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    char_max_length = 15\n",
    "    max_length = 475\n",
    "    word_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_word_sequence = pad_sequences(word_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    char_sequence = [[char_tokenizer.word_index.get(char, 0) for char in word] for word in sentence.split()]\n",
    "    char_sequence = pad_sequences(char_sequence, maxlen=char_max_length, padding=\"post\")\n",
    "    padded_char_sequence = pad_sequences([char_sequence], maxlen=max_length, padding='post', dtype='int32')\n",
    "    return padded_word_sequence, padded_char_sequence\n",
    "\n",
    "def predict_bad_words(sentence):\n",
    "    max_length = 475\n",
    "    padded_word_sequence, padded_char_sequence = preprocess_sentence(sentence)\n",
    "    predictions = model.predict([padded_word_sequence, padded_char_sequence])\n",
    "    threshold = 0.5\n",
    "    predicted_labels = (predictions > threshold).astype(int)[0]\n",
    "    words = sentence.split()\n",
    "    bad_words = [word for i, word in enumerate(words[:max_length]) if predicted_labels[i] == 1]\n",
    "    return bad_words\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return []\n",
    "    \n",
    "    model = Model(model_path)\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return []\n",
    "    \n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "    \n",
    "    word_timestamps = []\n",
    "    for result in results:\n",
    "        if 'result' in result:\n",
    "            for word_info in result['result']:\n",
    "                word_timestamps.append({\n",
    "                    'word': word_info.get('word', ''),\n",
    "                    'start': word_info.get('start', 0),\n",
    "                    'end': word_info.get('end', 0)\n",
    "                })\n",
    "    return word_timestamps\n",
    "\n",
    "def mute_bad_words_in_audio(audio_file, bad_words, word_timestamps):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    for item in word_timestamps:\n",
    "        if item['word'] in bad_words:\n",
    "            start_ms = item['start'] * 1000\n",
    "            end_ms = item['end'] * 1000\n",
    "            audio = audio[:start_ms] + AudioSegment.silent(duration=(end_ms - start_ms)) + audio[end_ms:]\n",
    "    muted_file = \"muted_\" + os.path.basename(audio_file)\n",
    "    audio.export(muted_file, format=\"wav\")\n",
    "    return muted_file\n",
    "\n",
    "# Integrate all steps\n",
    "audio_file = r\"M:\\Coding\\NLP_Project\\AudioData\\Audio_3009.wav\"\n",
    "model_path = 'vosk-model-small-hi-0.22'\n",
    "\n",
    "# Step 1: Transcribe audio with timestamps\n",
    "word_timestamps = transcribe_audio_with_timestamps(audio_file, model_path)\n",
    "\n",
    "# Step 2: Detect bad words from transcribed text\n",
    "transcribed_text = \" \".join([item['word'] for item in word_timestamps])  # Create sentence from transcribed words\n",
    "bad_words = predict_bad_words(transcribed_text)\n",
    "print(bad_words)\n",
    "\n",
    "# Step 3: Mute bad words in audio\n",
    "muted_file = mute_bad_words_in_audio(audio_file, bad_words, word_timestamps)\n",
    "print(f\"Muted audio saved to: {muted_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
