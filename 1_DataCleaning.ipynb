{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#unlock4guidelines - अनलॉक-4 के लिए गाइडलाइन्स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>पूर्व प्रधानमंत्री डॉ. मनमोहन सिंह ने 10 राजाज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>कुत्ते में भी एकता होती है विचारों में विरोध ह...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Filtered Sentences\n",
       "0  #unlock4guidelines - अनलॉक-4 के लिए गाइडलाइन्स...\n",
       "1  चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...\n",
       "2  बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...\n",
       "3  पूर्व प्रधानमंत्री डॉ. मनमोहन सिंह ने 10 राजाज...\n",
       "4  कुत्ते में भी एकता होती है विचारों में विरोध ह..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.lower()\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('\\n', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('\\[.*?\\]', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.strip()\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('@\\w+', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('<.*?>', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('http://\\S+|https://\\S+', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('\\[.*?\\]', '',regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace('\\n', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace(r'\\s*#\\w+\\s*', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace(r'\\b[a-zA-Z]+\\b', '', regex=True)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                             \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                             \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                             \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                             \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                             \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                             \"\\U0001F900-\\U0001F9FF\"  # Supplemental Emoji\n",
    "                             \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                             \"\\U00002702-\\U000027B0\"  # Miscellaneous Symbols\n",
    "                             \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'',text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "  punct = string.punctuation\n",
    "  punct = punct.replace(\"'\",\"\")\n",
    "  text = text.translate(str.maketrans(\"\", \"\",punct))\n",
    "  return text\n",
    "\n",
    "def number_to_words(text):\n",
    "  text_with_words = re.sub(r'\\d+', lambda x: p.number_to_words(x.group()), text)\n",
    "  return text_with_words \n",
    "\n",
    "\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].apply(remove_emoji)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].apply(remove_punctuation)\n",
    "data['Filtered Sentences'] = data['Filtered Sentences'].apply(number_to_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"CleanedFile.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(SnowballStemmer.languages)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The language 'hindi' is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowballStemmer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Hindi stemmer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m \u001b[43mSnowballStemmer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhindi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sample DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnotated Sentences\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mचूतिया चुतिये चूत\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     ]\n\u001b[0;32m     15\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\manan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\stem\\snowball.py:106\u001b[0m, in \u001b[0;36mSnowballStemmer.__init__\u001b[1;34m(self, language, ignore_stopwords)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, language, ignore_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguages:\n\u001b[1;32m--> 106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe language \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     stemmerclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[language\u001b[38;5;241m.\u001b[39mcapitalize() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStemmer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstemmer \u001b[38;5;241m=\u001b[39m stemmerclass(ignore_stopwords)\n",
      "\u001b[1;31mValueError\u001b[0m: The language 'hindi' is not supported."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Initialize the Hindi stemmer\n",
    "stemmer = SnowballStemmer(\"hindi\")\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Annotated Sentences': [\n",
    "        \"चूतिया चुतिये चूत\", \n",
    "        \"मादरचोद चूतिया\", \n",
    "        \"बेटा चुतिया है\", \n",
    "        \"गंदगी की बात मत करो\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to apply stemming\n",
    "def stem_sentence(sentence):\n",
    "    words = sentence.split()  # Split the sentence into words\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]  # Stem each word\n",
    "    return \" \".join(stemmed_words)  # Join back to a single string\n",
    "\n",
    "# Apply stemming to the 'Annotated Sentences' column\n",
    "df['Stemmed Sentences'] = df['Annotated Sentences'].apply(stem_sentence)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10124, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"annotated_bad_words.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered Sentences</th>\n",
       "      <th>Annotated Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अनलॉकfour के लिए गाइडलाइन्स जारी seven सितंबर...</td>\n",
       "      <td>अनलॉकfour के लिए गाइडलाइन्स जारी seven सितंबर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>चीन ने में तर्क दिया की भारत का विपक्ष ही अजर‌...</td>\n",
       "      <td>चीन ने में तर्क दिया की भारत का विपक्ष ही अजर‌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...</td>\n",
       "      <td>बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>पूर्व प्रधानमंत्री डॉ मनमोहन सिंह ने ten राजाज...</td>\n",
       "      <td>पूर्व प्रधानमंत्री डॉ मनमोहन सिंह ने ten राजाज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>कुत्ते में भी एकता होती है विचारों में विरोध ह...</td>\n",
       "      <td>&lt;bad_word&gt;&lt;bad_word&gt;&lt;bad_word&gt;कुत्ते&lt;/bad_word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>अरे कुत्ते किस मंदिर में खुदा को पूजा जाता है ...</td>\n",
       "      <td>अरे &lt;bad_word&gt;&lt;bad_word&gt;&lt;bad_word&gt;कुत्ते&lt;/bad_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>साला समझ मे नही आता की दुध पी रही है या वापिस ...</td>\n",
       "      <td>&lt;bad_word&gt;साला&lt;/bad_word&gt; समझ मे नही आता की दु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>सबसे बड़ा गधा तो को पोस्ट किया है वह है</td>\n",
       "      <td>सबसे बड़ा &lt;bad_word&gt;गधा&lt;/bad_word&gt; तो को पोस्ट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>अरे किसी के पास कोई काम धंधा नहीं है सब नवरे ब...</td>\n",
       "      <td>अरे किसी के पास कोई काम धंधा नहीं है सब नवरे ब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>भाई इन बातों से कोई फायदा नहीं गड़े मुर्दे हार...</td>\n",
       "      <td>भाई इन बातों से कोई फायदा नहीं गड़े मुर्दे हार...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Filtered Sentences  \\\n",
       "0       अनलॉकfour के लिए गाइडलाइन्स जारी seven सितंबर...   \n",
       "1      चीन ने में तर्क दिया की भारत का विपक्ष ही अजर‌...   \n",
       "2      बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...   \n",
       "3      पूर्व प्रधानमंत्री डॉ मनमोहन सिंह ने ten राजाज...   \n",
       "4      कुत्ते में भी एकता होती है विचारों में विरोध ह...   \n",
       "...                                                  ...   \n",
       "10119  अरे कुत्ते किस मंदिर में खुदा को पूजा जाता है ...   \n",
       "10120  साला समझ मे नही आता की दुध पी रही है या वापिस ...   \n",
       "10121            सबसे बड़ा गधा तो को पोस्ट किया है वह है   \n",
       "10122  अरे किसी के पास कोई काम धंधा नहीं है सब नवरे ब...   \n",
       "10123  भाई इन बातों से कोई फायदा नहीं गड़े मुर्दे हार...   \n",
       "\n",
       "                                     Annotated Sentences  \n",
       "0       अनलॉकfour के लिए गाइडलाइन्स जारी seven सितंबर...  \n",
       "1      चीन ने में तर्क दिया की भारत का विपक्ष ही अजर‌...  \n",
       "2      बियर ग्रिल्स के साथ खतरनाक जंगलों में दिखेंगे ...  \n",
       "3      पूर्व प्रधानमंत्री डॉ मनमोहन सिंह ने ten राजाज...  \n",
       "4      <bad_word><bad_word><bad_word>कुत्ते</bad_word...  \n",
       "...                                                  ...  \n",
       "10119  अरे <bad_word><bad_word><bad_word>कुत्ते</bad_...  \n",
       "10120  <bad_word>साला</bad_word> समझ मे नही आता की दु...  \n",
       "10121  सबसे बड़ा <bad_word>गधा</bad_word> तो को पोस्ट...  \n",
       "10122  अरे किसी के पास कोई काम धंधा नहीं है सब नवरे ब...  \n",
       "10123  भाई इन बातों से कोई फायदा नहीं गड़े मुर्दे हार...  \n",
       "\n",
       "[10122 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
