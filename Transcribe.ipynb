{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)  # Use PCM codec for export\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Check if the audio file is in WAV format\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract and print transcription with timestamps\n",
    "    for result in results:\n",
    "        if 'result' in result:  # Checking if word-level info is present\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown')\n",
    "                start_time = word_info.get('start', 0)\n",
    "                end_time = word_info.get('end', 0)\n",
    "                print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "transcribe_audio_with_timestamps(r'Audio_Data\\Audio_28.mp3', 'vosk-model-small-hi-0.22')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trascribe only Bad Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>Devanagari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aad</td>\n",
       "      <td>आंड़</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aand</td>\n",
       "      <td>आंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bahenchod</td>\n",
       "      <td>बहनचोद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>behenchod</td>\n",
       "      <td>बेहेनचोद</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bahen ka lauda</td>\n",
       "      <td>बेहेन्का लौडा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transliteration     Devanagari\n",
       "0             aad           आंड़\n",
       "1            aand            आंड\n",
       "2       bahenchod         बहनचोद\n",
       "3       behenchod       बेहेनचोद\n",
       "4  bahen ka lauda  बेहेन्का लौडा"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bad_words = pd.read_csv(\"BadWordListUpdated.csv\", encoding='utf-8')\n",
    "bad_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_list = bad_words['Devanagari'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio...\n",
      "Word: कुत्ते, Start: 0.12s, End: 0.39s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e) # Use PCM codec for export\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path, allowed_words):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = Model(model_path)\n",
    "\n",
    "    # Check if the audio file is in WAV format\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return\n",
    "\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)  # This line ensures word-level timestamps are included\n",
    "\n",
    "    print(\"Processing audio...\")\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "\n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract and print transcription with timestamps, filtering by allowed words\n",
    "    for result in results:\n",
    "        if 'result' in result:  # Checking if word-level info is present\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', 'Unknown').lower()\n",
    "                if word in allowed_words:  # Only keep allowed words\n",
    "                    start_time = word_info.get('start', 0)\n",
    "                    end_time = word_info.get('end', 0)\n",
    "                    print(f\"Word: {word}, Start: {start_time:.2f}s, End: {end_time:.2f}s\")\n",
    "        else:\n",
    "            print(\"No word-level results in this segment\")\n",
    "\n",
    "# Define the set of allowed words\n",
    "allowed_words = set(bad_word_list)\n",
    "\n",
    "# Run transcription with filtering\n",
    "transcribe_audio_with_timestamps(r\"Audio_Data\\Audio_4.mp3\", 'vosk-model-small-hi-0.22', allowed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: TempConvert\\Audio_0.wav\n",
      "Processing file: TempConvert\\Audio_1.wav\n",
      "Processing file: TempConvert\\Audio_2.wav\n",
      "Processing file: TempConvert\\Audio_3.wav\n",
      "Processing file: TempConvert\\Audio_4.wav\n",
      "Bad words with timestamps saved to bad_words_timestamps.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import subprocess\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model, allowed_words, filename):\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(f\"Audio file {audio_file} must be in WAV format mono PCM.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file {audio_file}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "    \n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract bad words with timestamps\n",
    "    bad_word_entries = []\n",
    "    for result in results:\n",
    "        if 'result' in result:\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', '').lower()\n",
    "                if word in allowed_words:\n",
    "                    bad_word_entries.append({\n",
    "                        \"file\": filename,\n",
    "                        \"word\": word,\n",
    "                        \"start\": word_info.get(\"start\", 0),\n",
    "                        \"end\": word_info.get(\"end\", 0)\n",
    "                    })\n",
    "    return bad_word_entries\n",
    "\n",
    "def process_audio_folder(folder_path, model_path, allowed_words):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "\n",
    "    model = Model(model_path)\n",
    "    all_bad_words = []\n",
    "\n",
    "    # Process each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.wav', '.mp3')):\n",
    "            audio_file = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Convert MP3 to WAV if needed\n",
    "            if filename.lower().endswith('.mp3'):\n",
    "                wav_file = os.path.splitext(audio_file)[0] + '.wav'\n",
    "                convert_mp3_to_wav(audio_file, wav_file)\n",
    "                audio_file = wav_file\n",
    "\n",
    "            print(f\"Processing file: {audio_file}\")\n",
    "            bad_words = transcribe_audio_with_timestamps(audio_file, model, allowed_words, filename)\n",
    "            all_bad_words.extend(bad_words)\n",
    "    \n",
    "    # Save all bad words with timestamps to a JSON file\n",
    "    with open(\"bad_words_timestamps.json\", \"w\") as json_file:\n",
    "        json.dump(all_bad_words, json_file, indent=4)\n",
    "    print(\"Bad words with timestamps saved to bad_words_timestamps.json\")\n",
    "\n",
    "# Define the set of allowed words\n",
    "allowed_words = set(bad_word_list)\n",
    "\n",
    "# Run transcription with filtering on a folder of audio files\n",
    "process_audio_folder(\"TempConvert\", 'vosk-model-small-hi-0.22', allowed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 2500/2500 [1:03:13<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad words with timestamps saved to bad_words_timestamps.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model, allowed_words, filename):\n",
    "    # Open the audio file\n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(f\"Audio file {audio_file} must be in WAV format mono PCM.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file {audio_file}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize recognizer with sample rate\n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "    \n",
    "    # Get the final result\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "\n",
    "    # Extract bad words with timestamps\n",
    "    bad_word_entries = []\n",
    "    for result in results:\n",
    "        if 'result' in result:\n",
    "            for word_info in result['result']:\n",
    "                word = word_info.get('word', '').lower()\n",
    "                if word in allowed_words:\n",
    "                    bad_word_entries.append({\n",
    "                        \"file\": filename,\n",
    "                        \"word\": word,\n",
    "                        \"start\": word_info.get(\"start\", 0),\n",
    "                        \"end\": word_info.get(\"end\", 0)\n",
    "                    })\n",
    "    return bad_word_entries\n",
    "\n",
    "def process_audio_folder(folder_path, model_path, allowed_words):\n",
    "    # Load the Vosk model\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "\n",
    "    model = Model(model_path)\n",
    "    all_bad_words = []\n",
    "\n",
    "    # Get a list of audio files in the folder\n",
    "    audio_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.wav', '.mp3'))]\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    with tqdm(total=len(audio_files), desc=\"Processing audio files\") as pbar:\n",
    "        for filename in audio_files:\n",
    "            audio_file = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Convert MP3 to WAV if needed\n",
    "            if filename.lower().endswith('.mp3'):\n",
    "                wav_file = os.path.splitext(audio_file)[0] + '.wav'\n",
    "                convert_mp3_to_wav(audio_file, wav_file)\n",
    "                audio_file = wav_file\n",
    "\n",
    "            bad_words = transcribe_audio_with_timestamps(audio_file, model, allowed_words, filename)\n",
    "            all_bad_words.extend(bad_words)\n",
    "            \n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Save all bad words with timestamps to a JSON file\n",
    "    with open(\"bad_words_timestamps2.json\", \"w\") as json_file:\n",
    "        json.dump(all_bad_words, json_file, indent=4)\n",
    "    print(\"Bad words with timestamps saved to bad_words_timestamps.json\")\n",
    "\n",
    "# Define the set of allowed words\n",
    "allowed_words = set(bad_word_list)\n",
    "\n",
    "# Run transcription with filtering on a folder of audio files\n",
    "process_audio_folder(\"TempAudioData\", 'vosk-model-small-hi-0.22', allowed_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
