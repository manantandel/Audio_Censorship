{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Load the tokenizers and model (assuming they're saved as shown earlier)\n",
    "with open('ft_word_tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('ft_char_tokenizer.pkl', 'rb') as handle:\n",
    "    char_tokenizer = pickle.load(handle)\n",
    "model = load_model('fast_text_bad_word_detection_model.h5')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    char_max_length = 15\n",
    "    max_length = 475\n",
    "    word_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_word_sequence = pad_sequences(word_sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    char_sequence = [[char_tokenizer.word_index.get(char, 0) for char in word] for word in sentence.split()]\n",
    "    char_sequence = pad_sequences(char_sequence, maxlen=char_max_length, padding=\"post\")\n",
    "    padded_char_sequence = pad_sequences([char_sequence], maxlen=max_length, padding='post', dtype='int32')\n",
    "    return padded_word_sequence, padded_char_sequence\n",
    "\n",
    "def predict_bad_words(sentence):\n",
    "    max_length = 475\n",
    "    padded_word_sequence, padded_char_sequence = preprocess_sentence(sentence)\n",
    "    predictions = model.predict([padded_word_sequence, padded_char_sequence])\n",
    "    threshold = 0.5\n",
    "    predicted_labels = (predictions > threshold).astype(int)[0]\n",
    "    words = sentence.split()\n",
    "    bad_words = [word for i, word in enumerate(words[:max_length]) if predicted_labels[i] == 1]\n",
    "    return bad_words\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-i', mp3_file, '-ac', '1', '-ar', '16000', wav_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during MP3 to WAV conversion:\", e)\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_file, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return []\n",
    "    \n",
    "    model = Model(model_path)\n",
    "    if not audio_file.lower().endswith('.wav'):\n",
    "        wav_file = audio_file.rsplit('.', 1)[0] + '.wav'\n",
    "        if audio_file.lower().endswith('.mp3'):\n",
    "            convert_mp3_to_wav(audio_file, wav_file)\n",
    "            audio_file = wav_file\n",
    "        else:\n",
    "            print(\"Audio file must be in WAV format or MP3 format.\")\n",
    "            return []\n",
    "    \n",
    "    try:\n",
    "        wf = wave.open(audio_file, \"rb\")\n",
    "        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "            print(\"Audio file must be WAV format mono PCM.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening audio file: {e}\")\n",
    "        return []\n",
    "    \n",
    "    rec = KaldiRecognizer(model, wf.getframerate())\n",
    "    rec.SetWords(True)\n",
    "    results = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            results.append(result)\n",
    "        else:\n",
    "            rec.PartialResult()\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    results.append(final_result)\n",
    "    \n",
    "    word_timestamps = []\n",
    "    for result in results:\n",
    "        if 'result' in result:\n",
    "            for word_info in result['result']:\n",
    "                word_timestamps.append({\n",
    "                    'word': word_info.get('word', ''),\n",
    "                    'start': word_info.get('start', 0),\n",
    "                    'end': word_info.get('end', 0)\n",
    "                })\n",
    "    return word_timestamps\n",
    "\n",
    "def mute_bad_words_in_audio(audio_file, bad_words, word_timestamps):\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    for item in word_timestamps:\n",
    "        if item['word'] in bad_words:\n",
    "            start_ms = item['start'] * 1000\n",
    "            end_ms = item['end'] * 1000\n",
    "            audio = audio[:start_ms] + AudioSegment.silent(duration=(end_ms - start_ms)) + audio[end_ms:]\n",
    "    muted_file = \"muted_\" + os.path.basename(audio_file)\n",
    "    audio.export(muted_file, format=\"wav\")\n",
    "    return muted_file\n",
    "\n",
    "# Integrate all steps\n",
    "audio_file = r\"M:\\Coding\\NLP_Project\\AudioData\\Audio_3009.wav\"\n",
    "model_path = 'vosk-model-small-hi-0.22'\n",
    "\n",
    "# Step 1: Transcribe audio with timestamps\n",
    "word_timestamps = transcribe_audio_with_timestamps(audio_file, model_path)\n",
    "\n",
    "# Step 2: Detect bad words from transcribed text\n",
    "transcribed_text = \" \".join([item['word'] for item in word_timestamps])  # Create sentence from transcribed words\n",
    "bad_words = predict_bad_words(transcribed_text)\n",
    "print(bad_words)\n",
    "\n",
    "# Step 3: Mute bad words in audio\n",
    "muted_file = mute_bad_words_in_audio(audio_file, bad_words, word_timestamps)\n",
    "print(f\"Muted audio saved to: {muted_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
